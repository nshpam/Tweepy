# ğŸ“Š Twitisen â€“ Your Twitterverse âœ¨ğŸ“²

In our Software Developer coursework, we utilized the Twitter API to collect tweet data and employed Natural Language Processing (NLP) for in-depth analysis. The program, designed with user-friendly principles, seamlessly integrates Python, Unittest for rigorous testing, and an Extract, Load, Transform (ELT) pipeline for efficient data processing. With a strong emphasis on data visualization techniques, we've created a versatile tool that not only collects Twitter data but also employs NLP for insightful analysis. The program doesn't just gather information; it transforms raw data into meaningful visualizations, showcasing trends and patterns derived from the Twitterverse. This project highlights our collaborative synergy in developing a comprehensive and effective computer program for Twitter data analysis and visualization. We store the data securely in MongoDB.

# Table of Contents
- [Lessons Learned ğŸ“](#lessons-learned-) <br>
- [Screenshots ğŸ“·](#screenshots-) <br>
- [GUI Designing ğŸ¨](#gui-designing-) <br>
- [Contributor ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»](#contributor-) <br>

## Lessons Learned ğŸ“  
[Back to top](#table-of-contents) <br>

### ğŸ§  NLP (Natural Language Processing) ğŸ§ 
- ğŸ“ˆ Implementing NLP techniques for sentiment analysis to gauge user opinions.
- âš™ï¸ **Filtering Unnecessary Data:** Removing emojis and special characters to clean the text.
- âœ‚ï¸ **Tokenization:** Breaking down text into individual tokens (words or phrases).
- âš–ï¸ **Normalization:** Converting verbs from their base form (Verb 3) to their infinitive form (Verb 1).
- â›” **Removing Stopwords:** Eliminating common words (e.g., "the," "and") that don't carry significant meaning.
- ğŸ“Š **Sentiment Analysis:** Determining the emotional tone or sentiment expressed in the text.

### Python Programming
- ğŸ Mastering Python for efficient scripting and data manipulation.
- ğŸ§ª Writing modular and reusable code for improved maintainability.
- ğŸŒ Utilizing Python for data extraction, transformation, and loading (ETL) processes.

### Twitter API
- ğŸ•Šï¸ Extracting data from Twitter using the Twitter API.
- ğŸ”„ Transforming raw Twitter data for analysis and visualization.

### GUI (Graphical User Interface)
- ğŸ–¥ï¸ Developing user-friendly graphical interfaces for data visualization.
- ğŸ¨ Enhancing user experience through intuitive design.

### Unittest
- ğŸ§ª Implementing unit tests for code reliability and robustness.
- ğŸš€ Ensuring the correctness of data extraction and transformation processes.

### Data Visualization
- ğŸ“Š Creating compelling visualizations to convey insights effectively.
- ğŸ“ˆ Using tools like Matplotlib or Plotly for graphical representation.

### ELT Pipeline (Extract, Load, Transform)
- ğŸš€ Designing and implementing efficient ELT pipelines.
- ğŸ”„ Extracting data from various sources, transforming it, and loading it into databases.

### MongoDB
- ğŸ—„ï¸ Storing and retrieving data efficiently using MongoDB.
- ğŸ” Ensuring data security and scalability.

## Screenshots ğŸ“·
[Back to top](#table-of-contents) <br>

### 
| **ğŸ›¢ï¸ğŸ”— ELT Pipeline ğŸ”—ğŸ›¢ï¸** |
|:---| 
| ![Exclusive Summary](https://github.com/nshpam/Tweepy/assets/97942535/5eb17cf8-64fd-432e-b80e-204c3b4959e5) |
|**Firstly,** we extract tweets from the Twitter API. The API provides information such as id, username, datetime, text, favorite count, retweet count, and location.<br>**Secondly,** we store the extracted data in MongoDB, referring to this dataset as raw data.<br>**Thirdly,** we apply a complex algorithm to transform the data. We filter out URL symbols, numeric symbols, emojis, and special characters using our custom implementation and Lexto+. Given the dataset's diverse language composition, our focus is solely on Thai and English. For Thai language, we tokenize and normalize using Lexto+, while for English, we utilize NLTK. We clean Thai stop words with PythaiNLP and English stop words with NLTK.<br>**Fourthly,** we store the cleaned data in MongoDB, naming this dataset as clean data.<br>**Lastly,** we utilize the cleaned data for data visualization. The visualization includes sentiments, a donut chart, word cloud, bar chart, and spatial chart, all of which are presented on the GUI.|

### 
| **ğŸ—‚ï¸ğŸ’½ Database Schema ğŸ’½ğŸ—‚ï¸** |
|:--:| 
| [Back to top](#table-of-contents) |
| ![](https://github.com/nshpam/Tweepy/assets/97942535/e8189a5d-6c9c-49d9-b71c-8321f7402025) |
|_We have four independent databases. The **'tweets'** database will contain raw data collected from the Twitter API. The **'cleaned_data'** database will store transformed or cleaned data. The **'locations'** database will include the location and coordinates of tweets. The **'sentiments'** database will house keywords that users use for searching in the Twitter search bar and the corresponding ranked results._|

| tweets      | cleaned_data | locations |  sentiments    |
|  :----:         |    :----:   |    :----:   |          :----:  |
| **PK:** id<br>**FK:** location      | **PK:** id       | **PK:** id   |**PK:** id |

### 
| **ğŸ”ğŸ§ Competitor Analysis ğŸ§ğŸ”** |
|:--:|
| [Back to top](#table-of-contents) |
| ![](https://github.com/nshpam/Tweepy/assets/97942535/8b424da2-23d6-4738-b834-0f814d7b1297) |
| _Before creating our pipeline, we conducted research on other competitors. We aimed to merge the strengths and improve the weaknesses identified during the analysis._ |

###
| **ğŸ¤–ğŸ“¥ Extracting Algorithm ğŸ“¥ğŸ¤–** |
|:--:|
| [Back to top](#table-of-contents) |
| ![extract](https://github.com/nshpam/Twitisen/assets/97942535/588c6f1c-0e39-48aa-a1a7-b2c8e4c749d1) |
| _The algorithm will sweep the timeline in periods of 14 days, creating a checkpoint. The extraction area will cover 7 days before the checkpoint and 7 days after the checkpoint._ |
| ![extract](https://github.com/nshpam/Twitisen/assets/97942535/3314fbee-e9ce-4e22-9c5f-c8f431ffe9e0) |
| _If it reaches the end of the timeline, the checkpoint will be set as the end date. In some cases, this may result in a duplicate extraction. However, there is no need to worry because we have an algorithm that checks whether the data has already been extracted. The algorithm compares the tweet ID of the desired tweet with the tweet ID in ypur database._ |


###
| **ğŸ“…ğŸ•‘ Timeline Classification ğŸ•‘ğŸ“…** |
|:--:|
| [Back to top](#table-of-contents) |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/0b81fcb3-2d63-4626-8e0b-a25435e68df9) |
| This is an example of how it actually works: the green line represents the checkpoints, This is a continuous timeline where each day is consecutive. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/f505b253-7cb0-47c3-924a-cd549c4f3d9a) |
| I've implemented a binary search for timeline classification, making it faster than the regular approach. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/9e833cea-7db0-4ea2-85cd-d75a72c05abf) |
| If the time period is an odd number of days, we will calculate the checkpoint using the following formula, as shown. In this process we will extract the checkpoint first. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/b335c54f-e441-4300-a8b7-7f881fc81e09) |
| From the checkpoint we will extract two date at the same time. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/82be072d-5eab-4207-b18f-ae6b110120c9) |
| If the time period is an even number of days, we will calculate the checkpoint using the following formula, as shown. In this process we will extract the checkpoints at the same time. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/5de089e7-fc07-4311-b4e5-ee221af37d28) |
| Like the previous one, from the checkpoint we will extract two date at the same time. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/b4639189-32f8-4448-ae7b-8a2b1f1cdbc3) |
| This is an example of how it actually works: the green line represents the checkpoints, This is a discrete timeline where each day is non-consecutive. We will calculate the checkpoint using the following formula, as shown.|
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/7e44bdcc-080b-45ed-ac6e-b40168a2314c) |
| Since we have two types of timelinesâ€”continuous and discrete. We use an algorithm to identify them. First, we sort the timeline, and then we check if the dates are consecutive. If they are, it's a continuous timeline; if not, it's a discrete timeline. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/7e618d7a-e0e9-4b2c-b2c6-7be3f31fc18b) |
| If the date difference is 1, it is considered consecutive. However, if it is not, the sum of consecutive differentials will be less than the length of the timeline. |
| ![timeline](https://github.com/nshpam/Twitisen/assets/97942535/7639f957-64b7-46b7-a577-72348ff54e7e) |
| Lastly, this is the difference between two timelines. |

## GUI Designing ğŸ¨
[Back to top](#table-of-contents) <br>
This is our initial design, sketched by hand. We created a rough draft of the GUI in a low-fidelity (Lofi) format and transform it into GUI using pyqt5. The disadvantage of this design is...
- No spatial chart
- Few options to extract data
- The search input field is too large.
- Shows only three tabs
- Bad layout
### 
| **ğŸ—œï¸ğŸ§© Prototype 1 ğŸ§©ğŸ—œï¸** |
|:--:|
| [Back to top](#table-of-contents) |
| ![prototype1](https://github.com/nshpam/Tweepy/assets/97942535/e70f31bd-9882-443d-9c76-c957cfde9929) |
| ![prototype1](https://github.com/nshpam/Tweepy/assets/97942535/0315c207-2eb3-4cfd-b24a-7ad7b4df383b) |
| ![prototype1](https://github.com/nshpam/Tweepy/assets/97942535/56ff2128-7225-40e8-913b-a3b10f280921) |
| ![GUI1](https://github.com/nshpam/Tweepy/assets/97942535/71ea1bf0-224d-4df9-a73f-4e1383e1e536) |
| ![GUI1](https://github.com/nshpam/Tweepy/assets/97942535/27408cee-97b3-4c11-b263-93da344bdf82) |
| ![GUI1](https://github.com/nshpam/Tweepy/assets/97942535/78de45f8-46ef-435c-a029-9135e44a8cd7) |

This is our second design. We created a rough draft of the GUI in a low-fidelity (Lofi) format and transform it into GUI using pyqt5. This time we named the program as Twitter Harvest and recolor it into darkmode. The disadvantage of this design is...
- There is an unnecessary push button.
- Too many separate pages make it difficult for users to use.
- The layout of the elements is inconsistent.
- Too many pushbuttons, difficult to use.
### 
| **ğŸ—œï¸ğŸ§© Prototype 2 ğŸ§©ğŸ—œï¸** |
|:--:|
| [Back to top](#table-of-contents) |
| ![prototype2](https://github.com/nshpam/Tweepy/assets/97942535/b6205ebc-2d51-4467-ac77-c40fa90de506) |
| ![prototype2](https://github.com/nshpam/Tweepy/assets/97942535/0dd149d8-1d86-438b-a258-d78a5ad00e06) |
| ![prototype2](https://github.com/nshpam/Tweepy/assets/97942535/a682bb45-3b51-43e6-872d-00ddb636c9c4) |
| ![prototype2](https://github.com/nshpam/Tweepy/assets/97942535/4bbabb69-0e48-4c64-98d0-f27f8b047681) |
| ![prototype2](https://github.com/nshpam/Tweepy/assets/97942535/0c119b90-da8e-40d9-abb4-b04eb6eb1d3b) |
| ![prototype2](https://github.com/nshpam/Tweepy/assets/97942535/4167519a-72c8-49ba-a336-6a87287c45c7) |

Description of prototype 3
### 
| **ğŸ—œï¸ğŸ§© Prototype 3 ğŸ§©ğŸ—œï¸** |
|:--:|
| [Back to top](#table-of-contents) |
| ![prototype3](https://github.com/nshpam/Tweepy/assets/97942535/33730fbc-6612-4598-9c00-0e512134500e) |
| ![prototype3](https://github.com/nshpam/Tweepy/assets/97942535/9a9d3df6-1a6e-426c-9afa-4041930ee1e1) | 
| ![prototype3](https://github.com/nshpam/Tweepy/assets/97942535/37c87d6d-1696-47bf-8116-7a6f63ee9f24) |
| ![prototype3](https://github.com/nshpam/Tweepy/assets/97942535/7bf4372c-6416-471d-bce1-ad8465afd585) |
| ![prototype3](https://github.com/nshpam/Tweepy/assets/97942535/8446e361-be86-49c2-9c74-95ebf2eb07e9) |
| ![prototype3](https://github.com/nshpam/Tweepy/assets/97942535/af2afb7e-284f-4e98-9c07-573dad61c1f4) |
| ![prototype3](https://github.com/nshpam/Twitisen/assets/97942535/ee2b0186-5d71-47c0-9890-3b4855885092) |
| ![prototype3](https://github.com/nshpam/Twitisen/assets/97942535/16040b85-13f2-4028-9b1e-96277388ac2a) |

Description of version 1.0
### 
| **ğŸ‰ğŸš€ Version 1.0 ğŸ‰ğŸš€** |
|:--:|
| [Back to top](#table-of-contents) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/376ed73e-85e9-4742-ac44-99b14f4f66d1) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/8af1e118-7524-4fed-b123-72ace78ab302) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/ebba16ac-97d0-4b04-ab7b-60c567f6bd0e) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/9da36b3f-f306-414f-ae5b-91cbeeb2a3cc) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/7fda138a-3677-411b-8df1-f0b3c704ff0a) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/4570e905-6886-430e-9832-2a234ec93fc9) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/76be9ac5-ebc4-4efd-9ed6-586d89fb86a2) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/fe03b3c5-3088-4f4d-becc-a987b3047359) |
| ![ver1](https://github.com/nshpam/Twitisen/assets/97942535/092b0e8e-3c4d-42bc-a3ef-5285e5ae76a7) |

## Contributor ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»
[Back to top](#table-of-contents) <br>
- [@nshpam](https://github.com/nshpam) [Back-End]
- [@tw94sh](https://github.com/tw94sh) [Front-End]
